{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Neural style transfer -\n",
    "    This code takes a base image and a style image and produces a\n",
    "    combination image which has content of the base image and style of the\n",
    "    style image(https://arxiv.org/pdf/1508.06576). This is achieved by\n",
    "    minimising two losses- content loss(measure error between base and\n",
    "    combination image pixel values) and style loss. The loss is minimised with\n",
    "    bfgs algorithm and we update pixel values of combination image instead of\n",
    "    weights of the network\n",
    "'''\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths for base_image and style_image\n",
    "base_image_path = './image1.jpg'\n",
    "style_reference_image_path = './image2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img1 = Image.open(base_image_path)\n",
    "img2 = Image.open(style_reference_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "a = fig.add_subplot(1,2,1)\n",
    "a.imshow(img1)\n",
    "a.set_title('Base Image')\n",
    "a = fig.add_subplot(1,2,2)\n",
    "a.imshow(img2)\n",
    "a.set_title('Style image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights for different loss funstions\n",
    "total_variation_weight = 1.0\n",
    "style_weight = 5.0\n",
    "content_weight = 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of the generated picture.\n",
    "width, height = load_img(base_image_path).size\n",
    "new_width = 512\n",
    "new_height = int(width * new_width / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path, target_size=(new_width, new_height))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x = x.reshape((new_height, new_width, 3))\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    # make sure values are between 0 and 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define various losses\n",
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = new_height * new_width\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "\n",
    "def content_loss(base, combination):\n",
    "    # MSE difference for base and combination image\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "\n",
    "\n",
    "def total_variation_loss(x):\n",
    "   \n",
    "    a = K.square(x[:, :new_width - 1, :new_height - 1, :] - x[:, 1:, :new_height - 1, :])\n",
    "    b = K.square(x[:, :new_width - 1, :new_height - 1, :] - x[:, :new_width - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, new_width, new_height, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1].flatten().astype('float64')\n",
    "    return loss_value, grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(\n",
    "    preprocess_image(style_reference_image_path))\n",
    "combination_image = K.placeholder((1, new_width, new_height, 3))\n",
    "\n",
    "# concatenate all three image tensors\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)\n",
    "# define vgg19 model instance\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = K.variable(0.)\n",
    "# get feature vector from block5 conv layer 2\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(base_image_features,\n",
    "                                      combination_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style features from layers defined in Gatys et al. (2015)\n",
    "# https://arxiv.org/pdf/1508.06576\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(feature_layers)) * sl\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the gradient of the losses wrt combination image\n",
    "grads = K.gradients(loss, combination_image)\n",
    "outputs = [loss]\n",
    "outputs += grads\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We then introduce an Evaluator class that computes loss and gradients in one\n",
    "pass while retrieving them via two separate functions, loss and grads.\n",
    "This is done because scipy.optimize requires separate functions for loss and\n",
    "gradients, but computing them separately would be inefficient.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the combination_image to be the content image produces better\n",
    "# results and leads to faster convergence than using a random image at the\n",
    "# start\n",
    "x = preprocess_image(base_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 30\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    # using l_bfgs to minimise loss instead of sgd (to make it converge faster)\n",
    "    # https://docs.scipy.org/doc/scipy/reference/generated/\n",
    "    #                                         scipy.optimize.fmin_l_bfgs_b.html\n",
    "    x, min_val, _ = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                  fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = 'img_at_iteration_%d.png' % i\n",
    "    # save image at each iteration\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
